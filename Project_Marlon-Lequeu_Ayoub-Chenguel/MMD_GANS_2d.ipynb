{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "def compute_pairwise_distance(x, y):\n",
        "    # Number of samples in each batch\n",
        "    n = x.size(0)\n",
        "    m = y.size(0)\n",
        "\n",
        "    # Squared norms of each row vector, reshaped for broadcasting\n",
        "    x_norm = (x**2).sum(dim=1).view(n, 1)\n",
        "    y_norm = (y**2).sum(dim=1).view(1, m)\n",
        "\n",
        "    # Pairwise squared distances using matrix multiplication for the cross term\n",
        "    return x_norm + y_norm - 2 * torch.mm(x, y.t())\n",
        "\n",
        "\n",
        "def rational_quadratic_kernel_matrix(x, y, alphas=None):\n",
        "    # Default mixture parameters if none are provided\n",
        "    if alphas is None:\n",
        "        alphas = [0.2, 1, 5]\n",
        "\n",
        "    # Compute all pairwise squared distances between x and y\n",
        "    pairwise_dists = compute_pairwise_distance(x, y)\n",
        "\n",
        "    # Sum multiple rational-quadratic kernels (mixture over different alphas)\n",
        "    kernel_sum = 0\n",
        "    for alpha in alphas:\n",
        "        kernel_sum += (1 + pairwise_dists / (2 * alpha)) ** (-alpha)\n",
        "\n",
        "    # Final kernel matrix\n",
        "    return kernel_sum\n"
      ],
      "metadata": {
        "id": "wokSNFBhPgvq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator maps a noise vector to a sample in the data space\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_dim=2, output_dim=2, hidden_dim=16):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            # First MLP layer: noise -> hidden representation\n",
        "            nn.Linear(noise_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            # Second MLP layer: increase modeling capacity\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            # Final projection to the desired output dimension\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        # Forward pass through the MLP\n",
        "        return self.model(z)\n",
        "\n",
        "\n",
        "# Critic maps an input sample to a feature embedding (used for scoring / losses)\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self, input_dim=2, feature_dim=16, hidden_dim=32):\n",
        "        super(Critic, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            # First MLP layer: input -> hidden representation\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            # Second MLP layer: deeper feature extraction\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            # Output feature vector (not a scalar score here)\n",
        "            nn.Linear(hidden_dim, feature_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through the MLP\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "id": "rBid3b-8pZ3Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mmd_loss(real_features, fake_features, kernel=rational_quadratic_kernel_matrix, sigmas=None):\n",
        "    # Kernel matrix for real-real similarities\n",
        "    K_XX = kernel(real_features, real_features, sigmas)\n",
        "\n",
        "    # Kernel matrix for fake-fake similarities\n",
        "    K_YY = kernel(fake_features, fake_features, sigmas)\n",
        "\n",
        "    # Kernel matrix for real-fake similarities\n",
        "    K_XY = kernel(real_features, fake_features, sigmas)\n",
        "\n",
        "    # Batch sizes\n",
        "    m = real_features.size(0)\n",
        "    n = fake_features.size(0)\n",
        "\n",
        "    # Biased MMD estimate (includes diagonal terms)\n",
        "    loss = K_XX.sum()/(m*m) + K_YY.sum()/(n*n) - 2*K_XY.sum()/(m*n)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def gradient_penalty(critic, real_data, fake_data, lambda_gp=1.0):\n",
        "    # Number of samples in the batch\n",
        "    batch_size = real_data.size(0)\n",
        "\n",
        "    # Random mixing weights per sample, expanded to match data shape\n",
        "    epsilon = torch.rand(batch_size, 1, device=device)\n",
        "    epsilon = epsilon.expand_as(real_data)\n",
        "\n",
        "    # Interpolated samples where the gradient constraint is enforced\n",
        "    interpolated = epsilon * real_data + (1 - epsilon) * fake_data\n",
        "    interpolated.requires_grad_(True)\n",
        "\n",
        "    # Critic output on interpolated samples\n",
        "    crit_interpolated = critic(interpolated)\n",
        "\n",
        "    # Sum outputs so autograd gives gradients for the whole batch in one call\n",
        "    crit_sum = crit_interpolated.sum()\n",
        "\n",
        "    # Gradients of the critic output w.r.t. interpolated inputs\n",
        "    gradients = grad(\n",
        "        outputs=crit_sum,\n",
        "        inputs=interpolated,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True\n",
        "    )[0]\n",
        "\n",
        "    # Flatten per sample to compute a per-sample norm\n",
        "    gradients = gradients.view(batch_size, -1)\n",
        "\n",
        "    # Per-sample L2 norm of the gradients\n",
        "    grad_norm = gradients.norm(2, dim=1)\n",
        "\n",
        "    # Penalty term encouraging the gradient norm to stay close to 1\n",
        "    penalty = lambda_gp * ((grad_norm - 1) ** 2).mean()\n",
        "    return penalty\n"
      ],
      "metadata": {
        "id": "t6Mj734AqLhN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize models\n",
        "noise_dim = 2\n",
        "G = Generator(noise_dim=noise_dim).to(device)\n",
        "C = Critic().to(device)"
      ],
      "metadata": {
        "id": "3VeW58Z1CR5E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate samples from the generator\n",
        "with torch.no_grad():\n",
        "    z = sample_noise(500, noise_dim)\n",
        "    gen_samples = G(z).cpu().numpy()\n",
        "\n",
        "# plot generated samples vs real data\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.scatter(X_real[:, 0].cpu(), X_real[:, 1].cpu(), alpha=0.5, label=\"Real Data\")\n",
        "plt.scatter(gen_samples[:, 0], gen_samples[:, 1], alpha=0.5, c= 'red', label=\"Generated Data\")\n",
        "plt.title(\"Real vs Generated Samples (MMD GAN)\")\n",
        "plt.legend()\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PKg1NN26qvFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from IPython.display import FileLink\n",
        "\n",
        "shutil.make_archive('2d', 'zip', 'samples/2d')\n",
        "\n",
        "FileLink(\"2d.zip\")"
      ],
      "metadata": {
        "id": "ANm4hxxtITvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('2d.zip')"
      ],
      "metadata": {
        "id": "YjH1SP2rIV7F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}